{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPivUMJvePwe37U3qcNQCuC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafijurrahmanmamun/Quantum-Machine-Learning-QML-for-binding-affinity-prediction-and-the-QUBO-formulation-/blob/main/QML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: setup\n",
        "\n",
        "%load_ext google.colab.data_table\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3ajamQltoRM",
        "outputId": "c266627a-ac16-46fe-fe8a-bd9bd56a1a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# #@title 1. Setup: Install Necessary Libraries\n",
        "# # Run this cell first to install all required packages.\n",
        "!pip install pennylane scikit-learn numpy rdkit-pypi pyqubo dwave-ocean-sdk simanneal\n",
        "\n",
        "print(\"Libraries installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7e-43iVt-Au",
        "outputId": "f3a64995-23cf-404d-8de6-fe9e4df7cee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.11/dist-packages (0.41.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: pyqubo in /usr/local/lib/python3.11/dist-packages (1.5.0)\n",
            "Requirement already satisfied: dwave-ocean-sdk in /usr/local/lib/python3.11/dist-packages (8.3.0)\n",
            "Requirement already satisfied: simanneal in /usr/local/lib/python3.11/dist-packages (0.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.16.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.7.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.41 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi) (11.2.1)\n",
            "Requirement already satisfied: dimod<0.13,>=0.9.14 in /usr/local/lib/python3.11/dist-packages (from pyqubo) (0.12.20)\n",
            "Requirement already satisfied: dwave-neal>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from pyqubo) (0.6.0)\n",
            "Requirement already satisfied: Deprecated>=1.2.12 in /usr/local/lib/python3.11/dist-packages (from pyqubo) (1.2.18)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from pyqubo) (1.17.0)\n",
            "Requirement already satisfied: dwave-cloud-client==0.13.4 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.13.4)\n",
            "Requirement already satisfied: dwave-gate==0.3.3 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.3.3)\n",
            "Requirement already satisfied: dwave-hybrid==0.6.14 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.6.14)\n",
            "Requirement already satisfied: dwave-inspector==0.5.3 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.5.3)\n",
            "Requirement already satisfied: dwave-networkx==0.8.17 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.8.17)\n",
            "Requirement already satisfied: dwave-optimization==0.6.0 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.6.0)\n",
            "Requirement already satisfied: dwave-preprocessing==0.6.8 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.6.8)\n",
            "Requirement already satisfied: dwave-samplers==1.5.0 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (1.5.0)\n",
            "Requirement already satisfied: dwave-system==1.30.0 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (1.30.0)\n",
            "Requirement already satisfied: dwavebinarycsp==0.3.1 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.3.1)\n",
            "Requirement already satisfied: minorminer==0.2.18 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (0.2.18)\n",
            "Requirement already satisfied: penaltymodel==1.2.0 in /usr/local/lib/python3.11/dist-packages (from dwave-ocean-sdk) (1.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (2.4.0)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (2.11.4)\n",
            "Requirement already satisfied: homebase<2,>=1.0 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (1.0.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (8.2.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (2.9.0.post0)\n",
            "Requirement already satisfied: plucky<0.5,>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (0.4.3)\n",
            "Requirement already satisfied: diskcache<6,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (5.6.3)\n",
            "Requirement already satisfied: werkzeug<4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (3.1.3)\n",
            "Requirement already satisfied: authlib<2,>=1.2 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (1.6.0)\n",
            "Requirement already satisfied: importlib_metadata>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (8.7.0)\n",
            "Requirement already satisfied: orjson>=3.10 in /usr/local/lib/python3.11/dist-packages (from dwave-cloud-client==0.13.4->dwave-ocean-sdk) (3.10.18)\n",
            "Requirement already satisfied: Flask<4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from dwave-inspector==0.5.3->dwave-ocean-sdk) (3.1.1)\n",
            "Requirement already satisfied: fasteners>=0.15 in /usr/local/lib/python3.11/dist-packages (from minorminer==0.2.18->dwave-ocean-sdk) (0.19)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated>=1.2.12->pyqubo) (1.17.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning>=0.41->pennylane) (0.3.29.265.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.4.26)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<2,>=1.2->dwave-cloud-client==0.13.4->dwave-ocean-sdk) (43.0.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4,>=2.2->dwave-inspector==0.5.3->dwave-ocean-sdk) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4,>=2.2->dwave-inspector==0.5.3->dwave-ocean-sdk) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4,>=2.2->dwave-inspector==0.5.3->dwave-ocean-sdk) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4,>=2.2->dwave-inspector==0.5.3->dwave-ocean-sdk) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=5.0.0->dwave-cloud-client==0.13.4->dwave-ocean-sdk) (3.21.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->dwave-cloud-client==0.13.4->dwave-ocean-sdk) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->dwave-cloud-client==0.13.4->dwave-ocean-sdk) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->dwave-cloud-client==0.13.4->dwave-ocean-sdk) (0.4.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]<3,>=2.25->dwave-cloud-client==0.13.4->dwave-ocean-sdk) (1.7.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<2,>=1.2->dwave-cloud-client==0.13.4->dwave-ocean-sdk) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<2,>=1.2->dwave-cloud-client==0.13.4->dwave-ocean-sdk) (2.22)\n",
            "Libraries installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UpKFN-ahtsMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title 2. Imports and Basic Configuration\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np # Use PennyLane's wrapped numpy for autograd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.decomposition import PCA # For potential feature reduction\n",
        "\n",
        "# RDKit (for cheminformatics - conceptual use here)\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "# QUBO related\n",
        "from pyqubo import Array, Placeholder, solve_qubo\n",
        "import neal # D-Wave's simulated annealer\n",
        "from simanneal import Annealer # For classical SA comparison\n",
        "import dimod # For BQM\n",
        "\n",
        "# Other\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# --- Configuration ---\n",
        "NUM_QUBITS_QML = 4\n",
        "NUM_FEATURES_QML = 4 # After PCA or selection, matching NUM_QUBITS_QML for AngleEmbedding\n",
        "QML_ANSATZ_LAYERS = 2 # Number of layers in the VQC ansatz\n",
        "\n",
        "NUM_EXCIPIENTS_QUBO = 20 # m in the paper\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "print(\"Imports successful and basic configuration set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVk9Lht6qUU8",
        "outputId": "a38a3c61-35a4-4dd7-dd56-b1066e89a17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports successful and basic configuration set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Data Generation/Loading (Placeholder for Davis Dataset)\n",
        "\n",
        "# --- Placeholder Data Generation ---\n",
        "# In a real scenario, you would:\n",
        "# 1. Load the Davis dataset (SMILES strings for ligands, protein info, Kd values).\n",
        "# 2. Calculate molecular descriptors (e.g., Morgan fingerprints using RDKit).\n",
        "# 3. Apply PCA or feature selection to get NUM_FEATURES_QML (e.g., 4) features.\n",
        "# 4. Convert Kd to pKd (e.g., -log10(Kd_molar)).\n",
        "\n",
        "N_SAMPLES = 100 # Small dataset for quick demo\n",
        "\n",
        "# Placeholder features (e.g., after PCA from molecular descriptors)\n",
        "X_placeholder = np.random.rand(N_SAMPLES, NUM_FEATURES_QML)\n",
        "\n",
        "# Placeholder target binding affinities (pKd values)\n",
        "# Simulating a relationship: y = sum(features) + noise\n",
        "y_placeholder = np.sum(X_placeholder, axis=1) + 0.1 * np.random.randn(N_SAMPLES)\n",
        "\n",
        "# Scale features and target (common practice for ML/QML)\n",
        "scaler_X = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X_placeholder)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "y_scaled = scaler_y.fit_transform(y_placeholder.reshape(-1, 1)).flatten()\n",
        "\n",
        "\n",
        "print(f\"Generated placeholder data: X_scaled shape: {X_scaled.shape}, y_scaled shape: {y_scaled.shape}\")\n",
        "\n",
        "# --- Conceptual RDKit + PCA (Illustrative - Not run with placeholder data) ---\n",
        "def get_morgan_fingerprints_and_pca(smiles_list, n_components=4):\n",
        "    \"\"\"\n",
        "    Conceptual function to get Morgan fingerprints and apply PCA.\n",
        "    This is for illustration; you'd need a real list of SMILES.\n",
        "    \"\"\"\n",
        "    if not smiles_list:\n",
        "        print(\"SMILES list is empty. Cannot generate fingerprints.\")\n",
        "        return None\n",
        "\n",
        "    mols = [Chem.MolFromSmiles(s) for s in smiles_list]\n",
        "    mols = [m for m in mols if m is not None] # Filter out invalid SMILES\n",
        "\n",
        "    if not mols:\n",
        "        print(\"No valid molecules from SMILES list. Cannot generate fingerprints.\")\n",
        "        return None\n",
        "\n",
        "    fps = []\n",
        "    for mol in mols:\n",
        "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048)\n",
        "        arr = np.zeros((1,), dtype=int) # For RDKit to convert to numpy\n",
        "        Chem.DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "        fps.append(arr)\n",
        "\n",
        "    if not fps:\n",
        "        print(\"No fingerprints generated.\")\n",
        "        return None\n",
        "\n",
        "    fps_np = np.array(fps)\n",
        "    pca = PCA(n_components=n_components)\n",
        "    principal_components = pca.fit_transform(fps_np)\n",
        "    print(f\"PCA explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "    return principal_components\n",
        "\n",
        "# Example SMILES (replace with your actual data)\n",
        "# example_smiles = [\"CCO\", \"c1ccccc1C(=O)O\", \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"]\n",
        "# if you had real SMILES, you could call:\n",
        "# X_real_features = get_morgan_fingerprints_and_pca(example_smiles, n_components=NUM_FEATURES_QML)\n",
        "# For this demo, we continue with X_scaled (placeholder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd3l6WjRrDeG",
        "outputId": "93149109-456f-4b84-b056-8a8b02321a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated placeholder data: X_scaled shape: (100, 4), y_scaled shape: (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Variational Quantum Circuit (VQC) Model - PennyLane\n",
        "\n",
        "# Define the quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=NUM_QUBITS_QML)\n",
        "\n",
        "# Define the VQC layers\n",
        "def feature_map(x):\n",
        "    \"\"\"Encodes classical features into quantum states.\"\"\"\n",
        "    qml.AngleEmbedding(features=x, wires=range(NUM_QUBITS_QML), rotation='X')\n",
        "\n",
        "def ansatz_layer(weights):\n",
        "    \"\"\"A single layer of the variational ansatz.\"\"\"\n",
        "    # Example: BasicEntanglerLayers structure\n",
        "    for i in range(NUM_QUBITS_QML):\n",
        "        qml.RY(weights[i], wires=i)\n",
        "    # This loop was causing the IndentationError due to missing code block\n",
        "    for i in range(NUM_QUBITS_QML - 1):\n",
        "        qml.CNOT(wires=[i, i + 1])\n",
        "    if NUM_QUBITS_QML > 1: # For ring connectivity if more than 1 qubit\n",
        "        qml.CNOT(wires=[NUM_QUBITS_QML - 1, 0])\n",
        "\n",
        "\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def vqc_model(weights, features):\n",
        "    \"\"\"The full VQC model.\"\"\"\n",
        "    feature_map(features)\n",
        "    for w_layer in weights: # weights is expected to be (num_layers, num_params_per_layer)\n",
        "        ansatz_layer(w_layer)\n",
        "\n",
        "    # Expectation value of Z0 Z1 Z2 Z3 (as per paper's Z^n)\n",
        "    # For simplicity, let's use expectation of Z on the first qubit as an example output.\n",
        "    # The paper uses Z^n, which for n=4 is Z0*Z1*Z2*Z3.\n",
        "    # This requires qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3)\n",
        "    # For a simpler regression output, often a single qubit observable or sum is used.\n",
        "    # Let's try to match the paper's Z^n observable.\n",
        "    if NUM_QUBITS_QML == 4:\n",
        "      obs = qml.PauliZ(0) @ qml.PauliZ(1) @ qml.PauliZ(2) @ qml.PauliZ(3)\n",
        "    else: # Fallback for different qubit numbers\n",
        "      obs = qml.PauliZ(0)\n",
        "    return qml.expval(obs)\n",
        "\n",
        "# Cost function (MSE)\n",
        "def square_loss(targets, predictions):\n",
        "    loss = 0\n",
        "    for t, p in zip(targets, predictions):\n",
        "        loss += (t - p) ** 2\n",
        "    loss = loss / len(targets)\n",
        "    return loss\n",
        "\n",
        "def cost_function(weights, X_batch, y_batch):\n",
        "    predictions = [vqc_model(weights, x) for x in X_batch]\n",
        "    return square_loss(y_batch, predictions)\n",
        "\n",
        "# Initialize weights for the VQC\n",
        "# Each layer of our example ansatz_layer has NUM_QUBITS_QML parameters (for RY gates)\n",
        "params_per_layer = NUM_QUBITS_QML\n",
        "initial_weights = np.random.randn(QML_ANSATZ_LAYERS, params_per_layer, requires_grad=True)\n",
        "\n",
        "print(f\"VQC model defined. Initial weights shape: {initial_weights.shape}\")\n",
        "# Test the VQC with one sample\n",
        "# print(f\"Test VQC output for one sample: {vqc_model(initial_weights, X_scaled)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHNulCxeuf-y",
        "outputId": "a5017ad1-c29c-4913-c59f-955c70641cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VQC model defined. Initial weights shape: (2, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. QML Model Training (Illustrative)\n",
        "\n",
        "# Split data for training and testing\n",
        "X_train_qml, X_test_qml, y_train_qml, y_test_qml = train_test_split(\n",
        "    X_scaled, y_scaled, test_size=0.2, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "opt = qml.AdamOptimizer(stepsize=0.1)\n",
        "batch_size = 10\n",
        "epochs = 20 # Keep low for quick demo\n",
        "\n",
        "weights_qml = np.copy(initial_weights) # Start with fresh weights\n",
        "\n",
        "print(\"Starting QML model training (illustrative)...\")\n",
        "for epoch in range(epochs):\n",
        "    for i in range(0, len(X_train_qml), batch_size):\n",
        "        X_batch = X_train_qml[i : i + batch_size]\n",
        "        y_batch = y_train_qml[i : i + batch_size]\n",
        "        weights_qml, _, _ = opt.step(cost_function, weights_qml, X_batch, y_batch) # Unpack cost from opt.step\n",
        "\n",
        "    # Cost on training data\n",
        "    train_predictions = [vqc_model(weights_qml, x) for x in X_train_qml]\n",
        "    current_cost = square_loss(y_train_qml, train_predictions)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Training Cost: {current_cost:.4f}\")\n",
        "\n",
        "print(\"QML training finished.\")\n",
        "\n",
        "# Evaluate QML model\n",
        "qml_predictions_test = np.array([vqc_model(weights_qml, x) for x in X_test_qml])\n",
        "qml_mse = mean_squared_error(y_test_qml, qml_predictions_test)\n",
        "qml_r2 = r2_score(y_test_qml, qml_predictions_test)\n",
        "\n",
        "print(f\"\\n--- QML Model Evaluation (on scaled test data) ---\")\n",
        "print(f\"MSE: {qml_mse:.4f}\")\n",
        "print(f\"R2 Score: {qml_r2:.4f}\")\n",
        "\n",
        "# To get predictions in original scale (if y was scaled)\n",
        "# qml_predictions_original_scale = scaler_y.inverse_transform(qml_predictions_test.reshape(-1,1)).flatten()\n",
        "# y_test_original_scale = scaler_y.inverse_transform(y_test_qml.reshape(-1,1)).flatten()\n",
        "# qml_mse_orig = mean_squared_error(y_test_original_scale, qml_predictions_original_scale)\n",
        "# print(f\"MSE (original scale): {qml_mse_orig:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm99ao9bu8A6",
        "outputId": "70626e0f-c840-42bf-bfae-5594236e711f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting QML model training (illustrative)...\n",
            "Epoch 5/20, Training Cost: 1.0236\n",
            "Epoch 10/20, Training Cost: 1.0178\n",
            "Epoch 15/20, Training Cost: 1.0170\n",
            "Epoch 20/20, Training Cost: 1.0169\n",
            "QML training finished.\n",
            "\n",
            "--- QML Model Evaluation (on scaled test data) ---\n",
            "MSE: 0.7116\n",
            "R2 Score: -0.0493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. Classical Baselines (Random Forest & SVR)\n",
        "\n",
        "# Use the same scaled data split as QML for fair comparison\n",
        "X_train_cl, X_test_cl, y_train_cl, y_test_cl = X_train_qml, X_test_qml, y_train_qml, y_test_qml\n",
        "\n",
        "# --- Random Forest Regressor ---\n",
        "print(\"\\n--- Random Forest Regressor ---\")\n",
        "rf_model = RandomForestRegressor(random_state=RANDOM_SEED)\n",
        "# Conceptual GridSearchCV (can be slow for demo)\n",
        "# param_grid_rf = {'n_estimators': [1, 2], 'max_depth': [None, 10]}\n",
        "# grid_rf = GridSearchCV(rf_model, param_grid_rf, cv=3, scoring='neg_mean_squared_error')\n",
        "# grid_rf.fit(X_train_cl, y_train_cl)\n",
        "# rf_model = grid_rf.best_estimator_\n",
        "# print(f\"Best RF params: {grid_rf.best_params_}\")\n",
        "\n",
        "rf_model.fit(X_train_cl, y_train_cl) # Fit with default or best params\n",
        "rf_predictions_test = rf_model.predict(X_test_cl)\n",
        "rf_mse = mean_squared_error(y_test_cl, rf_predictions_test)\n",
        "rf_r2 = r2_score(y_test_cl, rf_predictions_test)\n",
        "print(f\"RF Test MSE: {rf_mse:.4f}, R2 Score: {rf_r2:.4f}\")\n",
        "\n",
        "\n",
        "# --- Support Vector Regressor (SVR) ---\n",
        "print(\"\\n--- Support Vector Regressor ---\")\n",
        "svr_model = SVR()\n",
        "# Conceptual GridSearchCV\n",
        "# param_grid_svr = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}\n",
        "# grid_svr = GridSearchCV(svr_model, param_grid_svr, cv=3, scoring='neg_mean_squared_error')\n",
        "# grid_svr.fit(X_train_cl, y_train_cl)\n",
        "# svr_model = grid_svr.best_estimator_\n",
        "# print(f\"Best SVR params: {grid_svr.best_params_}\")\n",
        "\n",
        "svr_model.fit(X_train_cl, y_train_cl) # Fit with default or best params\n",
        "svr_predictions_test = svr_model.predict(X_test_cl)\n",
        "svr_mse = mean_squared_error(y_test_cl, svr_predictions_test)\n",
        "svr_r2 = r2_score(y_test_cl, svr_predictions_test)\n",
        "print(f\"SVR Test MSE: {svr_mse:.4f}, R2 Score: {svr_r2:.4f}\")\n",
        "\n",
        "# --- Summary Table (Conceptual, based on paper's format) ---\n",
        "# The paper reports MSE +/- std and R2 from 5-fold CV.\n",
        "# The above is a single train/test split. For full CV:\n",
        "# kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "# qml_mses, rf_mses, svr_mses =,,\n",
        "# qml_r2s, rf_r2s, svr_r2s =,,\n",
        "# for train_idx, test_idx in kf.split(X_scaled):\n",
        "#     X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "#     y_train, y_test = y_scaled[train_idx], y_scaled[test_idx]\n",
        "#     #... retrain and evaluate each model...\n",
        "# This full CV loop is omitted for brevity in this direct script.\n",
        "\n",
        "print(\"\\nNote: The paper's results (MSE +/- std, R2) are from 5-fold Cross-Validation.\")\n",
        "print(\"The evaluation above is based on a single train/test split for brevity.\")\n",
        "print(\"For a robust comparison, implement full k-fold CV for all models.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC8JIqpivO3U",
        "outputId": "154e9d33-d846-4ab3-d75a-1c90ea546bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Random Forest Regressor ---\n",
            "RF Test MSE: 0.1668, R2 Score: 0.7541\n",
            "\n",
            "--- Support Vector Regressor ---\n",
            "SVR Test MSE: 0.0738, R2 Score: 0.8912\n",
            "\n",
            "Note: The paper's results (MSE +/- std, R2) are from 5-fold Cross-Validation.\n",
            "The evaluation above is based on a single train/test split for brevity.\n",
            "For a robust comparison, implement full k-fold CV for all models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. QUBO Definition (using PyQUBO)\n",
        "\n",
        "# Placeholder coefficients for the QUBO\n",
        "# H = -sum(b_i*x_i) + lambda1*sum(t_ij*x_i*x_j) + lambda2*sum(s_i*x_i)\n",
        "# x_i are binary variables (0 or 1) for NUM_EXCIPIENTS_QUBO\n",
        "\n",
        "# Create binary variables for each excipient\n",
        "x = Array.create('x', shape=NUM_EXCIPIENTS_QUBO, vartype='BINARY')\n",
        "\n",
        "# Placeholder coefficients (randomly generated for this demo)\n",
        "# In a real scenario, these would come from experimental data, QSPR models, literature.\n",
        "# IMPORTANT: Ensure these are standard numpy arrays/floats, NOT PennyLane tensors\n",
        "# using the original numpy import alias (import numpy as np) is safer here.\n",
        "# Since we imported pennylane.numpy as np, let's convert them explicitly.\n",
        "\n",
        "# *** FIX START ***\n",
        "# Temporarily use standard numpy for generating coefficients to avoid PennyLane tensors\n",
        "import numpy as standard_np\n",
        "\n",
        "b_coeffs_np = standard_np.random.rand(NUM_EXCIPIENTS_QUBO).astype(float)      # Bioavailability (higher is better, so -b_i in QUBO)\n",
        "s_coeffs_np = (standard_np.random.rand(NUM_EXCIPIENTS_QUBO) * 0.5).astype(float) # Stability penalty (lower is better)\n",
        "t_coeffs_np = (standard_np.random.rand(NUM_EXCIPIENTS_QUBO, NUM_EXCIPIENTS_QUBO) * 0.2).astype(float) # Pairwise toxicity (lower is better)\n",
        "\n",
        "# Convert back to pennylane.numpy if needed elsewhere, but not for QUBO construction\n",
        "# The code below uses these standard numpy arrays directly, so no conversion back needed immediately.\n",
        "# *** FIX END ***\n",
        "\n",
        "\n",
        "standard_np.fill_diagonal(t_coeffs_np, 0) # No self-toxicity in pairwise term\n",
        "t_coeffs_np = standard_np.triu(t_coeffs_np, k=1) # Ensure t_ij = t_ji and only count pairs once\n",
        "\n",
        "# Placeholder lambda values (these need careful tuning via grid search in practice)\n",
        "lambda1_val = Placeholder('lambda1') # For toxicity\n",
        "lambda2_val = Placeholder('lambda2') # For stability\n",
        "\n",
        "# Construct the QUBO Hamiltonian using PyQUBO\n",
        "# Bioavailability term (maximize sum(b_i*x_i) -> minimize -sum(b_i*x_i))\n",
        "# Use standard numpy arrays/floats here\n",
        "term_bioavailability = -sum(b_coeffs_np[i] * x[i] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "\n",
        "# Toxicity term (minimize sum(t_ij*x_i*x_j))\n",
        "# Use standard numpy arrays/floats here\n",
        "term_toxicity = sum(t_coeffs_np[i, j] * x[i] * x[j]\n",
        "                    for i in range(NUM_EXCIPIENTS_QUBO)\n",
        "                    for j in range(i + 1, NUM_EXCIPIENTS_QUBO)) # Iterate over upper triangle\n",
        "\n",
        "# Stability term (minimize sum(s_i*x_i))\n",
        "# Use standard numpy arrays/floats here\n",
        "term_stability = sum(s_coeffs_np[i] * x[i] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "\n",
        "# Full Hamiltonian\n",
        "# This combination now involves PyQUBO expressions and Placeholders, which is compatible\n",
        "H = term_bioavailability + lambda1_val * term_toxicity + lambda2_val * term_stability\n",
        "\n",
        "# Compile the model to get QUBO coefficients (Q matrix)\n",
        "# Substitute placeholder lambda values for compilation\n",
        "feed_dict = {'lambda1': 1.0, 'lambda2': 1.0} # Example lambda values\n",
        "model = H.compile()\n",
        "Q, offset = model.to_qubo(feed_dict=feed_dict)\n",
        "\n",
        "print(f\"QUBO defined for {NUM_EXCIPIENTS_QUBO} excipients.\")\n",
        "print(f\"Number of variables in Q: {len(Q)}\")\n",
        "# print(\"Q matrix (sample):\", dict(list(Q.items())[:5])) # Show a few terms\n",
        "# print(\"Offset:\", offset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41VftDABvW9E",
        "outputId": "93d65ca8-75fb-43bf-da08-1dbcd85278b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUBO defined for 20 excipients.\n",
            "Number of variables in Q: 210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 8. QUBO Solving\n",
        "\n",
        "# --- 8.1 Using D-Wave's Simulated Annealer (Neal) ---\n",
        "# This simulates a quantum annealer's behavior classically.\n",
        "# For actual D-Wave QPU, use: from dwave.system import DWaveSampler, EmbeddingComposite\n",
        "# and sampler = EmbeddingComposite(DWaveSampler(token='YOUR_DWAVE_API_TOKEN'))\n",
        "\n",
        "sampler_neal = neal.SimulatedAnnealingSampler()\n",
        "start_time_neal = time.time()\n",
        "sampleset_neal = sampler_neal.sample_qubo(Q, num_reads=100) # num_reads for SA means num_runs\n",
        "end_time_neal = time.time()\n",
        "neal_time = end_time_neal - start_time_neal\n",
        "\n",
        "best_solution_neal = sampleset_neal.first.sample\n",
        "best_energy_neal = sampleset_neal.first.energy\n",
        "\n",
        "print(\"\\n--- D-Wave Neal (Simulated Annealer) ---\")\n",
        "print(f\"Time taken: {neal_time:.4f} seconds\")\n",
        "print(f\"Best energy: {best_energy_neal:.4f}\")\n",
        "# print(f\"Best solution (x_i values): {best_solution_neal}\")\n",
        "num_selected_neal = sum(best_solution_neal[f'x[{i}]'] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "print(f\"Number of excipients selected by Neal: {num_selected_neal}\")\n",
        "\n",
        "\n",
        "# --- 8.2 Classical Simulated Annealing (using simanneal library) ---\n",
        "# This is a separate classical SA implementation for comparison.\n",
        "class QUBOAnnealer(Annealer):\n",
        "    def __init__(self, state, qubo_dict):\n",
        "        self.qubo_dict = qubo_dict\n",
        "        super(QUBOAnnealer, self).__init__(state)\n",
        "\n",
        "    def move(self):\n",
        "        # Flip a random bit\n",
        "        idx_to_flip = np.random.randint(0, len(self.state))\n",
        "        self.state[idx_to_flip] = 1 - self.state[idx_to_flip]\n",
        "\n",
        "    def energy(self):\n",
        "        # Calculate QUBO energy: x^T Q x\n",
        "        current_energy = 0.0\n",
        "        # Linear terms (diagonal of Q)\n",
        "        for i in range(len(self.state)):\n",
        "            if (f'x[{i}]', f'x[{i}]') in self.qubo_dict:\n",
        "                 current_energy += self.qubo_dict[(f'x[{i}]', f'x[{i}]')] * self.state[i]\n",
        "        # Quadratic terms (off-diagonal of Q)\n",
        "        for i in range(len(self.state)):\n",
        "            for j in range(i + 1, len(self.state)):\n",
        "                if (f'x[{i}]', f'x[{j}]') in self.qubo_dict:\n",
        "                    current_energy += self.qubo_dict[(f'x[{i}]', f'x[{j}]')] * self.state[i] * self.state[j]\n",
        "        return current_energy + offset # Add the offset from PyQUBO compilation\n",
        "\n",
        "# Initial state for classical SA (random binary string)\n",
        "initial_state_sa = np.random.randint(0, 2, size=NUM_EXCIPIENTS_QUBO).tolist()\n",
        "\n",
        "# Convert Q from PyQUBO format (dict of tuples) to what QUBOAnnealer expects\n",
        "# Q from model.to_qubo() is already in a suitable dict format: {('x[i]', 'x[j]'): coeff}\n",
        "# We need to ensure the keys match the variable naming if we directly use `model.variables`\n",
        "# For simplicity, let's use the Q dict directly from model.to_qubo()\n",
        "\n",
        "sa = QUBOAnnealer(initial_state_sa, Q)\n",
        "sa.set_schedule(sa.auto(minutes=0.01)) # Short run for demo; tune Tmax, Tmin, steps for real use\n",
        "\n",
        "start_time_sa = time.time()\n",
        "best_state_sa, best_energy_sa = sa.anneal()\n",
        "end_time_sa = time.time()\n",
        "sa_time = end_time_sa - start_time_sa\n",
        "\n",
        "print(\"\\n--- Classical Simulated Annealer (simanneal library) ---\")\n",
        "print(f\"Time taken: {sa_time:.4f} seconds\")\n",
        "print(f\"Best energy: {best_energy_sa:.4f}\")\n",
        "# print(f\"Best solution (x_i values): {best_state_sa}\")\n",
        "num_selected_sa = sum(best_state_sa)\n",
        "print(f\"Number of excipients selected by classical SA: {num_selected_sa}\")\n",
        "\n",
        "# --- Benchmarking \"5x faster\" (Conceptual) ---\n",
        "if sa_time > 0 and neal_time > 0: # Avoid division by zero\n",
        "    speedup_factor = sa_time / neal_time\n",
        "    print(f\"\\nConceptual Speedup (Neal vs. Classical SA): {speedup_factor:.2f}x\")\n",
        "    print(\"(Note: This is illustrative. Real speedup depends on hardware, problem, and tuning.)\")\n",
        "else:\n",
        "    print(\"\\nCould not calculate speedup factor due to zero time for one of the solvers (likely too fast for this small problem).\")\n",
        "\n",
        "print(\"\\nReminder: The paper's '5x faster' claim is for D-Wave Leap (actual QPU) vs. a specific classical SA.\")\n",
        "print(\"Neal is a classical simulator. For QPU, use DWaveSampler with API token.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCKhPi4fv9MQ",
        "outputId": "3b35c195-ab62-41d6-ae90-b097f21f1e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
            "\r     0.00000         -3.00                         0:00:00            \r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- D-Wave Neal (Simulated Annealer) ---\n",
            "Time taken: 0.0730 seconds\n",
            "Best energy: -2.5210\n",
            "Number of excipients selected by Neal: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " Temperature        Energy    Accept   Improve     Elapsed   Remaining\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Classical Simulated Annealer (simanneal library) ---\n",
            "Time taken: 1.2056 seconds\n",
            "Best energy: -6.6075\n",
            "Number of excipients selected by classical SA: 15\n",
            "\n",
            "Conceptual Speedup (Neal vs. Classical SA): 16.52x\n",
            "(Note: This is illustrative. Real speedup depends on hardware, problem, and tuning.)\n",
            "\n",
            "Reminder: The paper's '5x faster' claim is for D-Wave Leap (actual QPU) vs. a specific classical SA.\n",
            "Neal is a classical simulator. For QPU, use DWaveSampler with API token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. Pareto Frontier and Lambda Grid Search (Conceptual)\n",
        "\n",
        "print(\"\\n--- Pareto Frontier and Lambda Grid Search (Conceptual) ---\")\n",
        "# To find the Pareto frontier, you would iterate over a grid of lambda1 and lambda2 values.\n",
        "# For each (lambda1, lambda2) pair:\n",
        "# 1. Re-compile the PyQUBO model: Q_new, offset_new = model.to_qubo(feed_dict={'lambda1': l1, 'lambda2': l2})\n",
        "# 2. Solve the new QUBO (e.g., using sampler_neal.sample_qubo(Q_new,...))\n",
        "# 3. Decode the solution and calculate the individual objective values:\n",
        "#    - Total Bioavailability = sum(b_coeffs[i] * x_sol[i])\n",
        "#    - Total Toxicity = sum(t_coeffs[i,j] * x_sol[i] * x_sol[j])\n",
        "#    - Total Stability = sum(s_coeffs[i] * x_sol[i])\n",
        "# 4. Collect all unique solutions and their objective values.\n",
        "# 5. Apply a non-dominated sorting algorithm to find the Pareto-optimal set.\n",
        "\n",
        "# Example lambda ranges (illustrative)\n",
        "lambda1_range = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
        "#@title 9. Pareto Frontier and Lambda Grid Search (Conceptual)\n",
        "\n",
        "print(\"\\n--- Pareto Frontier and Lambda Grid Search (Conceptual) ---\")\n",
        "# To find the Pareto frontier, you would iterate over a grid of lambda1 and lambda2 values.\n",
        "# For each (lambda1, lambda2) pair:\n",
        "# 1. Re-compile the PyQUBO model: Q_new, offset_new = model.to_qubo(feed_dict={'lambda1': l1, 'lambda2': l2})\n",
        "# 2. Solve the new QUBO (e.g., using sampler_neal.sample_qubo(Q_new,...))\n",
        "# 3. Decode the solution and calculate the individual objective values:\n",
        "#    - Total Bioavailability = sum(b_coeffs[i] * x_sol[i])\n",
        "#    - Total Toxicity = sum(t_coeffs[i,j] * x_sol[i] * x_sol[j])\n",
        "#    - Total Stability = sum(s_coeffs[i] * x_sol[i])\n",
        "# 4. Collect all unique solutions and their objective values.\n",
        "# 5. Apply a non-dominated sorting algorithm to find the Pareto-optimal set.\n",
        "\n",
        "# Example lambda ranges (illustrative)\n",
        "lambda1_range = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
        "lambda2_range = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "all_solutions_objectives = [] # Store (bioavailability, toxicity, stability, solution_vector)\n",
        "\n",
        "# Conceptual loop (not run for brevity)\n",
        "# for l1_val_current in lambda1_range:\n",
        "#     for l2_val_current in lambda2_range:\n",
        "#         current_feed_dict = {'lambda1': l1_val_current, 'lambda2': l2_val_current}\n",
        "#         Q_curr, offset_curr = model.to_qubo(feed_dict=current_feed_dict)\n",
        "#         sampleset_curr = sampler_neal.sample_qubo(Q_curr, num_reads=50)\n",
        "#         sol_dict = sampleset_curr.first.sample\n",
        "#         sol_vector = [sol_dict[f'x[{i}]'] for i in range(NUM_EXCIPIENTS_QUBO)]\n",
        "#\n",
        "#         # Calculate individual objectives for this solution\n",
        "#         current_bio = sum(b_coeffs[i] * sol_vector[i] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "#         current_tox = sum(t_coeffs[i, j] * sol_vector[i] * sol_vector[j]\n",
        "#                             for i in range(NUM_EXCIPIENTS_QUBO)\n",
        "#                             for j in range(i + 1, NUM_EXCIPIENTS_QUBO))\n",
        "#         current_stab = sum(s_coeffs[i] * sol_vector[i] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "#\n",
        "#         all_solutions_objectives.append({\n",
        "#             \"bioavailability\": current_bio, # Maximize this\n",
        "#             \"toxicity\": current_tox,       # Minimize this\n",
        "#             \"stability\": current_stab,     # Minimize this\n",
        "#             \"solution_vector\": sol_vector,\n",
        "#             \"lambdas\": (l1_val_current, l2_val_current)\n",
        "#         })\n",
        "#\n",
        "# # After collecting all_solutions_objectives, apply non-dominated sorting.\n",
        "# # This part is non-trivial to implement fully here.\n",
        "# print(f\"Conceptual: Collected {len(all_solutions_objectives)} solutions from lambda grid search (if run).\")\n",
        "print(\"A full Pareto frontier generation involves solving the QUBO for many lambda combinations\")\n",
        "print(\"and then filtering for non-dominated solutions.\")\n",
        "# 1. Re-compile the PyQUBO model: Q_new, offset_new = model.to_qubo(feed_dict={'lambda1': l1, 'lambda2': l2})\n",
        "# 2. Solve the new QUBO (e.g., using sampler_neal.sample_qubo(Q_new,...))\n",
        "# 3. Decode the solution and calculate the individual objective values:\n",
        "#    - Total Bioavailability = sum(b_coeffs[i] * x_sol[i])\n",
        "#    - Total Toxicity = sum(t_coeffs[i,j] * x_sol[i] * x_sol[j])\n",
        "#    - Total Stability = sum(s_coeffs[i] * x_sol[i])\n",
        "# 4. Collect all unique solutions and their objective values.\n",
        "# 5. Apply a non-dominated sorting algorithm to find the Pareto-optimal set.\n",
        "\n",
        "# Example lambda ranges (illustrative)\n",
        "lambda1_range = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
        "lambda2_range = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "all_solutions_objectives = [] # Store (bioavailability, toxicity, stability, solution_vector)\n",
        "\n",
        "# Conceptual loop (not run for brevity)\n",
        "# for l1_val_current in lambda1_range:\n",
        "#     for l2_val_current in lambda2_range:\n",
        "#         current_feed_dict = {'lambda1': l1_val_current, 'lambda2': l2_val_current}\n",
        "#         Q_curr, offset_curr = model.to_qubo(feed_dict=current_feed_dict)\n",
        "#         sampleset_curr = sampler_neal.sample_qubo(Q_curr, num_reads=50)\n",
        "#         sol_dict = sampleset_curr.first.sample\n",
        "#         sol_vector = [sol_dict[f'x[{i}]'] for i in range(NUM_EXCIPIENTS_QUBO)]\n",
        "#\n",
        "#         # Calculate individual objectives for this solution\n",
        "#         current_bio = sum(b_coeffs[i] * sol_vector[i] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "#         current_tox = sum(t_coeffs[i, j] * sol_vector[i] * sol_vector[j]\n",
        "#                             for i in range(NUM_EXCIPIENTS_QUBO)\n",
        "#                             for j in range(i + 1, NUM_EXCIPIENTS_QUBO))\n",
        "#         current_stab = sum(s_coeffs[i] * sol_vector[i] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "#\n",
        "#         all_solutions_objectives.append({\n",
        "#             \"bioavailability\": current_bio, # Maximize this\n",
        "#             \"toxicity\": current_tox,       # Minimize this\n",
        "#             \"stability\": current_stab,     # Minimize this\n",
        "#             \"solution_vector\": sol_vector,\n",
        "#             \"lambdas\": (l1_val_current, l2_val_current)\n",
        "#         })\n",
        "#\n",
        "# # After collecting all_solutions_objectives, apply non-dominated sorting.\n",
        "# # This part is non-trivial to implement fully here.\n",
        "# print(f\"Conceptual: Collected {len(all_solutions_objectives)} solutions from lambda grid search (if run).\")\n",
        "print(\"A full Pareto frontier generation involves solving the QUBO for many lambda combinations\")\n",
        "print(\"and then filtering for non-dominated solutions.\")\n",
        "# for l1_val_current in lambda1_range:\n",
        "#     for l2_val_current in lambda2_range:\n",
        "#         current_feed_dict = {'lambda1': l1_val_current, 'lambda2': l2_val_current}\n",
        "#         Q_curr, offset_curr = model.to_qubo(feed_dict=current_feed_dict)\n",
        "#         sampleset_curr = sampler_neal.sample_qubo(Q_curr, num_reads=50)\n",
        "#         sol_dict = sampleset_curr.first.sample\n",
        "#         sol_vector = [sol_dict[f'x[{i}]'] for i in range(NUM_EXCIPIENTS_QUBO)]\n",
        "#\n",
        "#         # Calculate individual objectives for this solution\n",
        "#         current_bio = sum(b_coeffs[i] * sol_vector[i] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "#         current_tox = sum(t_coeffs[i, j] * sol_vector[i] * sol_vector[j]\n",
        "#                             for i in range(NUM_EXCIPIENTS_QUBO)\n",
        "#                             for j in range(i + 1, NUM_EXCIPIENTS_QUBO))\n",
        "#         current_stab = sum(s_coeffs[i] * sol_vector[i] for i in range(NUM_EXCIPIENTS_QUBO))\n",
        "#\n",
        "#         all_solutions_objectives.append({\n",
        "#             \"bioavailability\": current_bio, # Maximize this\n",
        "#             \"toxicity\": current_tox,       # Minimize this\n",
        "#             \"stability\": current_stab,     # Minimize this\n",
        "#             \"solution_vector\": sol_vector,\n",
        "#             \"lambdas\": (l1_val_current, l2_val_current)\n",
        "#         })\n",
        "#\n",
        "# # After collecting all_solutions_objectives, apply non-dominated sorting.\n",
        "# # This part is non-trivial to implement fully here.\n",
        "# print(f\"Conceptual: Collected {len(all_solutions_objectives)} solutions from lambda grid search (if run).\")\n",
        "print(\"A full Pareto frontier generation involves solving the QUBO for many lambda combinations\")\n",
        "print(\"and then filtering for non-dominated solutions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RUFxK83wHLv",
        "outputId": "9f790c7a-7bb9-4cc9-bc17-8a8dbe51f411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Pareto Frontier and Lambda Grid Search (Conceptual) ---\n",
            "\n",
            "--- Pareto Frontier and Lambda Grid Search (Conceptual) ---\n",
            "A full Pareto frontier generation involves solving the QUBO for many lambda combinations\n",
            "and then filtering for non-dominated solutions.\n",
            "A full Pareto frontier generation involves solving the QUBO for many lambda combinations\n",
            "and then filtering for non-dominated solutions.\n",
            "A full Pareto frontier generation involves solving the QUBO for many lambda combinations\n",
            "and then filtering for non-dominated solutions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 10. Conclusion and Next Steps\n",
        "\n",
        "print(\"\\n--- Conclusion and Next Steps ---\")\n",
        "print(\"This Colab notebook provides a conceptual framework for the experiments in the paper.\")\n",
        "\n",
        "print(\"\\nFor QML Binding Affinity Prediction:\")\n",
        "print(\"- We used placeholder data. Real implementation requires Davis dataset processing, molecular descriptor calculation (e.g., RDKit), and PCA.\")\n",
        "print(\"- VQC training was illustrative. Robust results need full k-fold CV and potentially more epochs/tuning.\")\n",
        "print(\"- Classical baselines (RF, SVR) should also be tuned with GridSearchCV and evaluated with k-fold CV.\")\n",
        "\n",
        "print(\"\\nFor QUBO Drug Formulation:\")\n",
        "print(\"- QUBO coefficients (b_i, t_ij, s_i) were placeholders. These need to be derived from domain knowledge or predictive models.\")\n",
        "print(\"- D-Wave Neal was used for simulated annealing. For actual quantum annealing, use DWaveSampler with an API token.\")\n",
        "print(\"- The classical SA comparison and '5x faster' claim require careful, matched benchmarking against a well-tuned classical SA and specific D-Wave hardware.\")\n",
        "print(\"- Pareto frontier generation requires a systematic grid search over lambda parameters and non-dominated sorting.\")\n",
        "\n",
        "print(\"\\nTo extend this work:\")\n",
        "print(\"1. Integrate real data for QML.\")\n",
        "print(\"2. Implement robust k-fold CV and statistical comparisons for QML.\")\n",
        "print(\"3. Develop realistic QUBO coefficients.\")\n",
        "print(\"4. If D-Wave access is available, run QUBOs on a QPU.\")\n",
        "print(\"5. Implement the full Pareto frontier generation and analysis.\")\n",
        "print(\"6. Rigorously benchmark QA vs. classical SA for the QUBOs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIkt4I3fwaBy",
        "outputId": "5a2c3a17-720b-4de7-a08e-af0d7f833210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Conclusion and Next Steps ---\n",
            "This Colab notebook provides a conceptual framework for the experiments in the paper.\n",
            "\n",
            "For QML Binding Affinity Prediction:\n",
            "- We used placeholder data. Real implementation requires Davis dataset processing, molecular descriptor calculation (e.g., RDKit), and PCA.\n",
            "- VQC training was illustrative. Robust results need full k-fold CV and potentially more epochs/tuning.\n",
            "- Classical baselines (RF, SVR) should also be tuned with GridSearchCV and evaluated with k-fold CV.\n",
            "\n",
            "For QUBO Drug Formulation:\n",
            "- QUBO coefficients (b_i, t_ij, s_i) were placeholders. These need to be derived from domain knowledge or predictive models.\n",
            "- D-Wave Neal was used for simulated annealing. For actual quantum annealing, use DWaveSampler with an API token.\n",
            "- The classical SA comparison and '5x faster' claim require careful, matched benchmarking against a well-tuned classical SA and specific D-Wave hardware.\n",
            "- Pareto frontier generation requires a systematic grid search over lambda parameters and non-dominated sorting.\n",
            "\n",
            "To extend this work:\n",
            "1. Integrate real data for QML.\n",
            "2. Implement robust k-fold CV and statistical comparisons for QML.\n",
            "3. Develop realistic QUBO coefficients.\n",
            "4. If D-Wave access is available, run QUBOs on a QPU.\n",
            "5. Implement the full Pareto frontier generation and analysis.\n",
            "6. Rigorously benchmark QA vs. classical SA for the QUBOs.\n"
          ]
        }
      ]
    }
  ]
}